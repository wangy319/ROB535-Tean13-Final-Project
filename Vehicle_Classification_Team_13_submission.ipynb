{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vehicle_Classification_Team_13_submission.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wangy319/ROB535-Tean13-Final-Project/blob/main/Vehicle_Classification_Team_13_submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYpgrm0pnaNJ"
      },
      "source": [
        "# Vehicle Classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtvsJ7i-nh7T"
      },
      "source": [
        "## Setup Code\n",
        "Before getting started, we need to run some boilerplate code to set up our environment, same as Assignment 1. You'll need to rerun this setup code each time you start the notebook.\n",
        "\n",
        "First, run this cell load the autoreload extension. This allows us to edit .py source files, and re-import them into the notebook for a seamless editing and debugging experience."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bg9VZzWnkKy"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoTVKIpIoXfN"
      },
      "source": [
        "### Google Colab Setup\n",
        "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
        "\n",
        "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!) and copy the authorization code into the text box that appears below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r86XOsdncr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97cd368-05ad-4148-8322-ccc4db51aa3c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIUWKfK6oeIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59aa946b-6e0b-4912-920f-6d19f69ef1cf"
      },
      "source": [
        "import os\n",
        "\n",
        "# TODO: Fill in the Google Drive path where you uploaded the assignment\n",
        "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'ROB 535: Self Driving Car Final Project/'\n",
        "GOOGLE_DRIVE_PATH = os.path.join('drive', 'Shared drives', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
        "print(os.listdir(GOOGLE_DRIVE_PATH))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dataset', 'perception', 'result', 'Meeting Agenda.gdoc', 'Controls ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeCiVA0-p_kH"
      },
      "source": [
        "## Transfer Learning and Fine Tuning of ResNet architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COJu3Z7oqIUQ"
      },
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils as utils\n",
        "import cv2\n",
        "import sys, os, time, copy\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "sys.path.append(GOOGLE_DRIVE_PATH)\n",
        "\n",
        "os.environ[\"TZ\"] = \"US/Eastern\"\n",
        "time.tzset()\n",
        "\n",
        "# random seed\n",
        "seed = 2021\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r89eNhtBroIY"
      },
      "source": [
        "### Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL_MjTOIux2I"
      },
      "source": [
        "class VehicleDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root, train=True, image_height=224): # TODO: adjust image size\n",
        "        \n",
        "        self.root = root\n",
        "        self.train = train\n",
        "        self.image_height = image_height;\n",
        "\n",
        "        self.test_path = os.path.join(self.root, \"test\")\n",
        "        self.train_val_path = os.path.join(self.root, \"trainval\")\n",
        "        self.image_transform = transforms.Compose([\n",
        "                        # transforms.ToPILImage(),\n",
        "                        transforms.Resize(self.image_height),\n",
        "                        # transforms.Grayscale(),\n",
        "                        transforms.ToTensor()\n",
        "                        # transforms.Normalize(  # TODO: calculate this\n",
        "                        # \tmean=[0.4], # statistics calculated over 7scenes training set, should generalize fairly well\n",
        "                        # \tstd=[0.25]\n",
        "                        # \t)\n",
        "                        ])\n",
        "        \n",
        "        if train:\n",
        "            # labels\n",
        "            labels_path = os.path.join(self.train_val_path, \"labels.csv\")\n",
        "            labels = []   # 0, 1, 2\n",
        "            self.ids = []   # 'ee2d1ee9-dd1d-4e63-9881-19205c5dae27/0001'\n",
        "            with open(labels_path, 'r') as csvfile:\n",
        "                reader = csv.reader(csvfile, skipinitialspace=True)\n",
        "                next(reader)\n",
        "                for row in reader:\n",
        "                    labels.append(int(row[1]))\n",
        "                    self.ids.append(row[0])\n",
        "            \n",
        "            self.labels = np.zeros((len(labels), 3))\n",
        "            for i, label in enumerate(labels):\n",
        "                self.labels[i][label] = 1\n",
        "            \n",
        "        else: # test\n",
        "            next(os.walk(self.test_path))\n",
        "            self.ids = []\n",
        "            for root, dirs, files in os.walk(self.test_path):\n",
        "                path = root.split(os.sep)[-1]\n",
        "                # print(path)\n",
        "                # print(files)\n",
        "                img_ids = [f[:4] for f in files if f.endswith('.jpg')]\n",
        "                file_list = [os.path.join(path, id) for id in img_ids]\n",
        "                self.ids.extend(file_list)\n",
        "            # print(self.ids)\n",
        "            # print(len(self.ids))\n",
        "            \n",
        "        # self.bboxes = np.loadtxt(os.path.join(root, \"boxes.txt\")).reshape(60, 17, 4)   # (60, 17, 4)\n",
        "        # self.labels = np.loadtxt(os.path.join(root, \"labels.txt\"), dtype=np.int64)    # (60, 17) (1s, 2s) 1-crop, 2-weed\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.train:\n",
        "            # load images\n",
        "            img_path = os.path.join(self.train_val_path, self.ids[idx]+\"_image.jpg\")\n",
        "            img = Image.open(img_path).convert(\"RGB\") # w*h*3\n",
        "            img = self.image_transform(img)\n",
        "            labelarray = np.array([self.labels[idx]])\n",
        "            label = torch.tensor(labelarray)\n",
        "\n",
        "            return img, label\n",
        "        else:\n",
        "            img_path = os.path.join(self.test_path, self.ids[idx]+\"_image.jpg\")\n",
        "            img = Image.open(img_path).convert(\"RGB\") # w*h*3\n",
        "            img = self.image_transform(img)\n",
        "            return img, self.ids[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Definition\n",
        "\n",
        "Class Resnet18 is a modified version of the original Resnet18 architecture. \n"
      ],
      "metadata": {
        "id": "15qNxZij6gLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Resnet18(nn.Module):\n",
        "    def __init__(self, num_classes=3, use_pretrained=True):\n",
        "        super(Resnet18, self).__init__()\n",
        "        self.model = models.resnet18(pretrained=use_pretrained)\n",
        "        # self.model.avgpool = None\n",
        "        num_ftrs = self.model.fc.in_features\n",
        "        self.model.fc = torch.nn.Linear(num_ftrs, 256)\n",
        "        self.classifier_layer = nn.Sequential(\n",
        "            # nn.Linear(512, 256), # use the original linear layer on ResNet18\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 128), \n",
        "            nn.ReLU(), # batchnorm after activation yields better result\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "      batch_size ,_,_,_ = x.shape     #taking out batch_size from input image\n",
        "      x = self.model(x)\n",
        "\n",
        "      x = self.classifier_layer(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "UgO-ziggYEgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XE4W5-1AUdK"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "def initialize_model(model_name, num_classes=3, feature_extract=False, use_pretrained=True, input_size=224):\n",
        "    if model_name == 'resnet18':\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = torch.nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = input_size\n",
        "\n",
        "    elif model_name == \"resnet18_modified\":\n",
        "        model_ft = Resnet18(num_classes)\n",
        "        \n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8ZokzrNE1eK"
      },
      "source": [
        "### Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0cfcedME3a1"
      },
      "source": [
        "def train_model(model, dataloaders, loss_func, optimizer, num_epochs=25, is_inception=False, result_path=\"./\"):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        # for phase in ['train', 'val']:\n",
        "        for phase in ['train']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in tqdm(dataloaders[phase]):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    outputs = model(inputs)\n",
        "\n",
        "                    labels = labels.reshape(-1, 3)\n",
        "\n",
        "                    loss = loss_func(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    _, labels_max = torch.max(labels, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels_max.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "        \n",
        "            # save every model\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(best_model_wts, os.path.join(result_path, str(epoch)))\n",
        "\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    # print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsrVZ0XjrqH_"
      },
      "source": [
        "# Configs\n",
        "image_height = 512\n",
        "# image_height = 32\n",
        "num_classes = 3\n",
        "TRAIN = True\n",
        "num_epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "data_path = os.path.join(GOOGLE_DRIVE_PATH, \"dataset/\" + \"rob535-fall2021-final-project-data\")\n",
        "\n",
        "# Dataset initalization\n",
        "dataset = VehicleDataset(data_path, train=TRAIN, image_height=image_height) # 7574\n",
        "split_train_val = round(len(dataset)*0.9)\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [split_train_val, len(dataset)-split_train_val])\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                            train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "                            val_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "data_loaders = {}\n",
        "data_loaders['train'] = train_loader;\n",
        "data_loaders['val'] = val_loader;\n",
        "\n",
        "# Model Initialization - original/modified resnet18 architecture\n",
        "model,_ = initialize_model(model_name=\"resnet18_modified\", feature_extract=False, num_classes=num_classes, input_size=image_height)\n",
        "# model,_ = initialize_model(model_name=\"resnet18\", feature_extract=False, num_classes=num_classes, input_size=image_height)\n",
        "\n",
        "# print(model) # uncomment this line to view model architecture\n",
        "model.to(device)\n",
        "\n",
        "# construct an optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.Adam(params, lr=0.0005, \n",
        "                             betas=(0.9, 0.999), eps=1e-08, weight_decay=0.000005)\n",
        "\n",
        "# and a learning rate scheduler which decreases the learning rate by\n",
        "# 10x every 3 epochs\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                               step_size=3,\n",
        "                                               gamma=0.1)\n",
        "\n",
        "# Setup the loss fxn\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train and evaluate\n",
        "result_path = os.path.join(GOOGLE_DRIVE_PATH, \"result\")\n",
        "model_ft, hist = train_model(model, data_loaders, loss_func, optimizer, num_epochs=num_epochs, result_path=result_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following cell to visualize model architecture - Original ResNet18"
      ],
      "metadata": {
        "id": "Ln1yskCo7SZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model,_ = initialize_model(model_name=\"resnet18\", feature_extract=False, num_classes=num_classes, input_size=image_height)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "3PmfzLYScPNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following cell to visualize model architecture - Modified ResNet18"
      ],
      "metadata": {
        "id": "aVbh3DJa7f6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model,_ = initialize_model(model_name=\"resnet18_modified\", feature_extract=False, num_classes=num_classes, input_size=image_height)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "SYSTnVCbcS_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PBnQfLPfgwr"
      },
      "source": [
        "### Model Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8rtQlb5l4WP"
      },
      "source": [
        "def evaluate_model(model, test_loader, result_path, save=False):\n",
        "    model.eval()\n",
        "\n",
        "    if save:\n",
        "        # save predictions\n",
        "        rows = []\n",
        "\n",
        "        for inputs, id in tqdm(test_loader):\n",
        "            # print(id)\n",
        "            inputs = inputs.to(device)\n",
        "            \n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.set_grad_enabled(False):\n",
        "                # Get model outputs and calculate loss\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                rows.append([id[0], preds.item()])\n",
        "\n",
        "        # name of csv file \n",
        "        filename = os.path.join(result_path, \"13.csv\")\n",
        "        fields = [\"guid/image\", \"label\"]\n",
        "        # writing to csv file \n",
        "        with open(filename, 'w') as csvfile: \n",
        "            # creating a csv writer object \n",
        "            csvwriter = csv.writer(csvfile) \n",
        "            # writing the fields \n",
        "            csvwriter.writerow(fields) \n",
        "            # writing the data rows \n",
        "            csvwriter.writerows(rows)\n",
        "\n",
        "    else:\n",
        "        for inputs, id in tqdm(test_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.set_grad_enabled(False):\n",
        "                # Get model outputs and calculate loss\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                \n",
        "                print(\"id \", id)\n",
        "                print(\"preds \", preds.item())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following cell to generate predictions for test set. \n",
        "\n",
        "Update \"data_path\", \"result_path\" and \"evaluation_epoch\" to desired saved model.\n",
        "\n",
        "Setting $save$ to True will generate the .csv file and save in the \"result_path\".\n",
        "\n",
        "```\n",
        "evaluate_model(model, test_loader, result_path, save=True)\n",
        "```"
      ],
      "metadata": {
        "id": "hMvvPR5N7mrD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52wb3TRMvQpS"
      },
      "source": [
        "# Configs\n",
        "image_height = 512\n",
        "# image_height = 32\n",
        "num_classes = 3\n",
        "TRAIN = False\n",
        "EVAL = True\n",
        "num_epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "data_path = os.path.join(GOOGLE_DRIVE_PATH, \"dataset/\" + \"rob535-fall2021-final-project-data\")\n",
        "result_path = os.path.join(GOOGLE_DRIVE_PATH, \"result/\"+\"modified_weight_decay\")\n",
        "evaluation_epoch = \"11\"\n",
        "\n",
        "# Dataset initalization\n",
        "test_dataset = VehicleDataset(data_path, train=False, image_height=image_height) # 7574\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "                            test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
        "\n",
        "# construct an optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.Adam(params, lr=0.0005, \n",
        "                             betas=(0.9, 0.999), eps=1e-08, weight_decay=0.000005)\n",
        "\n",
        "# Model Initialization\n",
        "model,_ = initialize_model(model_name=\"resnet18_modified\", feature_extract=False, num_classes=num_classes, input_size=image_height)\n",
        "model.load_state_dict(torch.load(os.path.join(result_path, \"1\"), map_location=torch.device('cpu'))) #  map_location=torch.device('cpu') can be commented out if using gpu\n",
        "model.to(device)\n",
        "\n",
        "# print(\"len(test_loader)\", len(test_loader))\n",
        "\n",
        "evaluate_model(model, test_loader, result_path, save=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}